{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671bd66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoca 1/3 (9 batch-uri):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 1:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import Aer\n",
    "from qiskit.circuit.library import TwoLocal\n",
    "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# ----------------------- 1. VQC Cuantic cu parametri -----------------------\n",
    "class VQCCircuit:\n",
    "\n",
    "    # Initializeaza un circuit cuantic cu 16 qubiti\n",
    "    # Foloseste un circuit variational (TwoLocal) cu rotatii Ry si entanglement CZ\n",
    "    def __init__(self, kernel_size, backend, shots=128):\n",
    "        self.n_qubits = 16  # 2^4 pentru RawFeatureVector\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "\n",
    "        # Parametrii circuitului sunt initial random\n",
    "\n",
    "        self.params = np.random.uniform(0, 2 * np.pi, size=self.n_qubits * 2)\n",
    "\n",
    "        self.vqc = TwoLocal(num_qubits=self.n_qubits,\n",
    "                            rotation_blocks='ry',\n",
    "                            entanglement_blocks='cz',\n",
    "                            reps=1,\n",
    "                            parameter_prefix='θ')\n",
    "\n",
    "    def run(self, data):\n",
    "\n",
    "        # Normalizeaza patch-ul si il codifica in circuit\n",
    "        # Ruleaza circuitul si returneaza o valoare scalara medie pe baza masuratorii\n",
    "       \n",
    "        data = data.flatten().astype(np.float64)\n",
    "\n",
    "        if not np.all(np.isfinite(data)):\n",
    "            return 0.0  # fallback safe value\n",
    "\n",
    "        norm = np.linalg.norm(data)\n",
    "        if norm == 0 or np.isnan(norm):\n",
    "            return 0.0  # patch complet negru = output neutru\n",
    "\n",
    "        data = data / norm\n",
    "\n",
    "        if len(data) < self.n_qubits:\n",
    "            data = np.pad(data, (0, self.n_qubits - len(data)))\n",
    "        elif len(data) > self.n_qubits:\n",
    "            data = data[:self.n_qubits]\n",
    "\n",
    "        # Construim un feature map care ia vectorul normalizat si-l pune in stare cuantica\n",
    "\n",
    "        feature_map = RawFeatureVector(self.n_qubits)\n",
    "        feature_map = feature_map.assign_parameters(data)\n",
    "\n",
    "        qc = QuantumCircuit(self.n_qubits)\n",
    "        qc.compose(feature_map, inplace=True)\n",
    "\n",
    "        vqc_bound = self.vqc.assign_parameters(self.params)\n",
    "        qc.compose(vqc_bound, inplace=True)\n",
    "\n",
    "        qc.measure_all()\n",
    "\n",
    "        transpiled = transpile(qc, self.backend)\n",
    "        job = self.backend.run(transpiled, shots=self.shots)\n",
    "        result = job.result()\n",
    "        counts = result.get_counts()\n",
    "\n",
    "        total = sum(sum(int(bit) for bit in key) * val for key, val in counts.items())\n",
    "        return total / (self.shots * self.n_qubits)\n",
    "\n",
    "# -------------------------- 2. Funcția Forward -----------------------------\n",
    "class QuanvFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, quantum_circuits, kernel_size):\n",
    "         # Aplica circuitele cuantice pe fiecare patch din imagine\n",
    "        batch_size = inputs.shape[0]\n",
    "        length_x = inputs.shape[2] - kernel_size + 1\n",
    "        length_y = inputs.shape[3] - kernel_size + 1\n",
    "        outputs = torch.zeros(batch_size, len(quantum_circuits), length_x, length_y).to(inputs.device)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            for c, circuit in enumerate(quantum_circuits):\n",
    "                for x in range(length_x):\n",
    "                    for y in range(length_y):\n",
    "                        patch = inputs[i, 0, x:x+kernel_size, y:y+kernel_size]\n",
    "                        outputs[i, c, x, y] = circuit.run(patch.cpu().detach().numpy())\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return None, None, None\n",
    "\n",
    "# ---------------------------- 3. Stratul Cuantic ----------------------------\n",
    "class QuanvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(QuanvLayer, self).__init__()\n",
    "        # Creeaza un strat cuantic cu mai multe circuite (cate unul pe canal)\n",
    "        backend = Aer.get_backend('aer_simulator')\n",
    "        self.quantum_circuits = [VQCCircuit(kernel_size, backend) for _ in range(out_channels)]\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def forward(self, x):\n",
    "         # Aplica stratul cuantic personalizat pe input\n",
    "        return QuanvFunction.apply(x, self.quantum_circuits, self.kernel_size)\n",
    "\n",
    "# -------------------------- 4. Dataset Custom -----------------------------\n",
    "MAX_SAMPLES = 9\n",
    "\n",
    "class CTPatchDataset(Dataset):\n",
    "      # Incarca imaginile din directoare structurate pe clase si le eticheteaza\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        label_map = {}\n",
    "        label_id = 0\n",
    "\n",
    "        for label_name in os.listdir(root_dir):\n",
    "            class_dir = os.path.join(root_dir, label_name)\n",
    "            if not os.path.isdir(class_dir):\n",
    "                continue\n",
    "\n",
    "            key = label_name.strip().lower().replace(\" \", \"\")\n",
    "            if key not in label_map:\n",
    "                label_map[key] = label_id\n",
    "                label_id += 1\n",
    "\n",
    "            label = label_map[key]\n",
    "\n",
    "            for fname in os.listdir(class_dir):\n",
    "                if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    img_path = os.path.join(class_dir, fname)\n",
    "                    self.samples.append((img_path, label))\n",
    "\n",
    "        self.samples = self.samples[:MAX_SAMPLES]\n",
    "        if len(self.samples) == 0:\n",
    "            raise ValueError(\"Dataset-ul nu conține imagini valide.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# -------------------------- 5. Modelul Hibrid ------------------------------\n",
    "class HybridNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridNet, self).__init__()\n",
    "        self.quanv = QuanvLayer(1, 1, kernel_size=3)\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
    "\n",
    "        dummy = torch.zeros(1, 1, 28, 28)\n",
    "        with torch.no_grad():\n",
    "            x = self.forward_features(dummy)\n",
    "            self.flatten_dim = x.view(1, -1).shape[1]\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 3)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.quanv(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# -------------------------- 6. Antrenare ------------------------------\n",
    "\n",
    "# Defineste transformarile pentru imagini\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = CTPatchDataset(r\"C:\\Users\\Luchi\\Desktop\\LicentaCompleta\\Imagini\\QNNTrain\", transform=transform)\n",
    "batch_size = 1\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 3\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_batches = len(dataloader)\n",
    "    print(f\"\\n Epoca {epoch+1}/{epochs} ({total_batches} batch-uri):\")\n",
    "\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=total_batches, desc=f\"Epoca {epoch+1}\")\n",
    "    for batch_idx, (inputs, labels) in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = running_loss / total_batches\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\" Epoca {epoch+1} finalizată. Loss mediu: {avg_loss:.4f}\")\n",
    "\n",
    "# -------------------------- 7. Evaluare ------------------------------\n",
    "model_save_path = \"hybrid_quantum_model.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\" Model salvat în '{model_save_path}'\")\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(1, epochs+1), loss_history, marker='o')\n",
    "plt.title(\"Evoluția Loss-ului pe epoci\")\n",
    "plt.xlabel(\"Epoca\")\n",
    "plt.ylabel(\"Loss mediu\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Matrice confuzie\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Matricea de Confuzie\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit import Parameter\n",
    "from qiskit_aer import Aer\n",
    "from qiskit.circuit.library import TwoLocal\n",
    "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# ----------------------- 1. VQC Cuantic cu parametri -----------------------\n",
    "class VQCCircuit:\n",
    "    def __init__(self, kernel_size, backend, shots=1024):\n",
    "        self.n_qubits = kernel_size ** 2\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "\n",
    "        # Parametri trainabili ai circuitului\n",
    "        self.params = np.random.uniform(0, 2 * np.pi, size=self.n_qubits * 2)\n",
    "\n",
    "        # Circuit variational: rotații și entanglement\n",
    "        self.vqc = TwoLocal(num_qubits=self.n_qubits,\n",
    "                            rotation_blocks='ry',\n",
    "                            entanglement_blocks='cz',\n",
    "                            reps=1,\n",
    "                            parameter_prefix='θ')\n",
    "\n",
    "    def run(self, data):\n",
    "        data = data.flatten()\n",
    "        norm = np.linalg.norm(data)\n",
    "        if norm != 0:\n",
    "            data = data / norm\n",
    "\n",
    "        # Codificare prin amplitudini\n",
    "        feature_map = RawFeatureVector(self.n_qubits)\n",
    "        qc = QuantumCircuit(self.n_qubits)\n",
    "        qc.compose(feature_map.bind_parameters(data), inplace=True)\n",
    "        qc.compose(self.vqc.bind_parameters(self.params), inplace=True)\n",
    "        qc.measure_all()\n",
    "\n",
    "        transpiled = transpile(qc, self.backend)\n",
    "        job = self.backend.run(transpiled, shots=self.shots)\n",
    "        result = job.result()\n",
    "        counts = result.get_counts()\n",
    "\n",
    "        total = sum(sum(int(bit) for bit in key) * val for key, val in counts.items())\n",
    "        return total / (self.shots * self.n_qubits)\n",
    "\n",
    "# -------------------------- 2. Funcția Forward -----------------------------\n",
    "class QuanvFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, quantum_circuits, kernel_size):\n",
    "        batch_size = inputs.shape[0]\n",
    "        length_x = inputs.shape[2] - kernel_size + 1\n",
    "        length_y = inputs.shape[3] - kernel_size + 1\n",
    "        outputs = torch.zeros(batch_size, len(quantum_circuits), length_x, length_y).to(inputs.device)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            for c, circuit in enumerate(quantum_circuits):\n",
    "                for x in range(length_x):\n",
    "                    for y in range(length_y):\n",
    "                        patch = inputs[i, 0, x:x+kernel_size, y:y+kernel_size]\n",
    "                        outputs[i, c, x, y] = circuit.run(patch.cpu().detach().numpy())\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return None, None, None\n",
    "\n",
    "# ---------------------------- 3. Stratul Cuantic ----------------------------\n",
    "class QuanvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(QuanvLayer, self).__init__()\n",
    "        backend = Aer.get_backend('aer_simulator')\n",
    "        self.quantum_circuits = [VQCCircuit(kernel_size, backend) for _ in range(out_channels)]\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return QuanvFunction.apply(x, self.quantum_circuits, self.kernel_size)\n",
    "\n",
    "# -------------------------- 4. Dataset Custom -----------------------------\n",
    "MAX_SAMPLES = 30\n",
    "\n",
    "class CTPatchDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        label_map = {}\n",
    "        label_id = 0\n",
    "\n",
    "        for label_name in os.listdir(root_dir):\n",
    "            class_dir = os.path.join(root_dir, label_name)\n",
    "            if not os.path.isdir(class_dir):\n",
    "                continue\n",
    "\n",
    "            key = label_name.strip().lower().replace(\" \", \"\")\n",
    "            if key not in label_map:\n",
    "                label_map[key] = label_id\n",
    "                label_id += 1\n",
    "\n",
    "            label = label_map[key]\n",
    "\n",
    "            for fname in os.listdir(class_dir):\n",
    "                if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    img_path = os.path.join(class_dir, fname)\n",
    "                    self.samples.append((img_path, label))\n",
    "\n",
    "        self.samples = self.samples[:MAX_SAMPLES]\n",
    "        if len(self.samples) == 0:\n",
    "            raise ValueError(\"Dataset-ul nu conține imagini valide.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# -------------------------- 5. Modelul Hibrid ------------------------------\n",
    "class HybridNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridNet, self).__init__()\n",
    "        self.quanv = QuanvLayer(1, 1, kernel_size=3)\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
    "\n",
    "        dummy = torch.zeros(1, 1, 28, 28)\n",
    "        with torch.no_grad():\n",
    "            x = self.forward_features(dummy)\n",
    "            self.flatten_dim = x.view(1, -1).shape[1]\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 3)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.quanv(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# -------------------------- 6. Antrenare ------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = CTPatchDataset(\"/Imagini/QNNTrain\", transform=transform)\n",
    "batch_size = 2\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 5\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_batches = len(dataloader)\n",
    "    print(f\"\\n Epoch {epoch+1}/{epochs} ({total_batches} batch-uri):\")\n",
    "\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=total_batches, desc=f\"Epoca {epoch+1}\")\n",
    "    for batch_idx, (inputs, labels) in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = running_loss / total_batches\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\" Epoch {epoch+1} finalizat. Loss mediu: {avg_loss:.4f}\")\n",
    "\n",
    "# Salvare model\n",
    "model_save_path = \"hybrid_quantum_model.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\" Model salvat în '{model_save_path}'\")\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(1, epochs+1), loss_history, marker='o')\n",
    "plt.title(\"Evoluția Loss-ului pe epoci\")\n",
    "plt.xlabel(\"Epoca\")\n",
    "plt.ylabel(\"Loss mediu\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Matrice confuzie\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Matricea de Confuzie\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca01e92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 1. Salvează modelul PyTorch\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhybrid_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Model salvat ca hybrid_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 2. Evaluare pe datele de antrenare (sau test dacă ai)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Salvează modelul PyTorch\n",
    "torch.save(model.state_dict(), \"hybrid_model.pth\")\n",
    "print(\" Model salvat ca hybrid_model.pth\")\n",
    "\n",
    "# 2. Evaluare pe datele de antrenare (sau test dacă ai)\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_losses = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        all_losses.append(loss.item())\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 3. Afișare Confusion Matrix și Acuratețe\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(f\" Acuratețe: {acc*100:.2f}%\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Benign', 'Malignant', 'Normal'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Matrice de Confuzie\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Afișare loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(all_losses, marker='o')\n",
    "plt.title(\"Loss per Batch\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2cd389d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hybrid_net.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hybrid_net.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit_aer import Aer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------------------------- 1. Circuit Cuantic -----------------------------\n",
    "class QuanvCircuit:\n",
    "    def __init__(self, kernel_size, backend, shots=10, threshold=0.5):\n",
    "        self.n_qubits = kernel_size ** 2\n",
    "        self.theta = [Parameter(f'theta{i}') for i in range(self.n_qubits)]\n",
    "        self.circuit = QuantumCircuit(self.n_qubits)\n",
    "        for i in range(self.n_qubits):\n",
    "            self.circuit.rx(self.theta[i], i)\n",
    "        self.circuit.barrier()\n",
    "        self.circuit.h(range(self.n_qubits))\n",
    "        self.circuit.measure_all()\n",
    "\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def run(self, data):\n",
    "        data = data.flatten()\n",
    "        param_dict = {self.theta[i]: np.pi if data[i] > self.threshold else 0.0 for i in range(self.n_qubits)}\n",
    "        bound_circuit = self.circuit.assign_parameters(param_dict, inplace=False)\n",
    "        transpiled = transpile(bound_circuit, self.backend)\n",
    "        job = self.backend.run(transpiled, shots=self.shots)\n",
    "        result = job.result()\n",
    "        counts = result.get_counts()\n",
    "        total = sum(sum(int(bit) for bit in key) * val for key, val in counts.items())\n",
    "        return total / (self.shots * self.n_qubits)\n",
    "\n",
    "# -------------------------- 2. Funcție Forward Quanv --------------------------\n",
    "class QuanvFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, quantum_circuits, kernel_size):\n",
    "        batch_size = inputs.shape[0]\n",
    "        length_x = inputs.shape[2] - kernel_size + 1\n",
    "        length_y = inputs.shape[3] - kernel_size + 1\n",
    "        outputs = torch.zeros(batch_size, len(quantum_circuits), length_x, length_y).to(inputs.device)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            for c, circuit in enumerate(quantum_circuits):\n",
    "                for x in range(length_x):\n",
    "                    for y in range(length_y):\n",
    "                        patch = inputs[i, 0, x:x+kernel_size, y:y+kernel_size]\n",
    "                        outputs[i, c, x, y] = circuit.run(patch.cpu().detach().numpy())\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return None, None, None\n",
    "\n",
    "# ---------------------------- 3. Stratul Cuantic ------------------------------\n",
    "class QuanvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(QuanvLayer, self).__init__()\n",
    "        backend = Aer.get_backend('aer_simulator')\n",
    "        self.quantum_circuits = [QuanvCircuit(kernel_size, backend) for _ in range(out_channels)]\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return QuanvFunction.apply(x, self.quantum_circuits, self.kernel_size)\n",
    "\n",
    "\n",
    "class HybridNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridNet, self).__init__()\n",
    "        self.quanv = QuanvLayer(1, 1, kernel_size=3)\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
    "\n",
    "        # Init temporar pentru a determina automat dimensiunea FC\n",
    "        self._dummy_input = torch.zeros(1, 1, 28, 28)  # same shape as your dataset images\n",
    "        with torch.no_grad():\n",
    "            x = self.forward_features(self._dummy_input)\n",
    "            self.flatten_dim = x.view(1, -1).shape[1]\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 3)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.quanv(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
