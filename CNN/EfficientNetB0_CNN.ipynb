{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb6307c",
   "metadata": {},
   "source": [
    "Librarii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fef159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.applications import EfficientNetB0, efficientnet\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f8f74b",
   "metadata": {},
   "source": [
    "Setări"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b66d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224,224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_TOP = 40\n",
    "EPOCHS_FINE = 40\n",
    "SEED=42\n",
    "DATASET_PATH=\"Imagini/TrainImages\"\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5157bad",
   "metadata": {},
   "source": [
    "Încărcare date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d30e5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find directory Imagini/TrainImages",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDATASET_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m      6\u001b[0m     DATASET_PATH, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m, seed\u001b[38;5;241m=\u001b[39mSEED,\n\u001b[0;32m      7\u001b[0m     image_size\u001b[38;5;241m=\u001b[39mIMG_SIZE, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m class_names \u001b[38;5;241m=\u001b[39m train_ds\u001b[38;5;241m.\u001b[39mclass_names\n",
      "File \u001b[1;32mc:\\Users\\Luchi\\anaconda3\\envs\\CNN_Classic\\lib\\site-packages\\keras\\utils\\image_dataset.py:192\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m   seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m--> 192\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    202\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    203\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    204\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Luchi\\anaconda3\\envs\\CNN_Classic\\lib\\site-packages\\keras\\utils\\dataset_utils.py:66\u001b[0m, in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m   subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 66\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m     68\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Luchi\\anaconda3\\envs\\CNN_Classic\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:766\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \n\u001b[0;32m    753\u001b[0m \u001b[38;5;124;03mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;124;03m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(path):\n\u001b[1;32m--> 766\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[0;32m    767\u001b[0m       node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    768\u001b[0m       op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    769\u001b[0m       message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find directory \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path))\n\u001b[0;32m    771\u001b[0m \u001b[38;5;66;03m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;66;03m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    774\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str_any(filename)\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m _pywrap_file_io\u001b[38;5;241m.\u001b[39mGetChildren(compat\u001b[38;5;241m.\u001b[39mpath_to_bytes(path))\n\u001b[0;32m    776\u001b[0m ]\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find directory Imagini/TrainImages"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATASET_PATH, validation_split=0.2, subset=\"training\", seed=SEED,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH_SIZE\n",
    ")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATASET_PATH, validation_split=0.2, subset=\"validation\", seed=SEED,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH_SIZE\n",
    ")\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d048fa5",
   "metadata": {},
   "source": [
    "Numărare imagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcdb9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Train:\", sum(len(x) for x, _ in train_ds))\n",
    "print(\" Val:\", sum(len(x) for x, _ in val_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66040f33",
   "metadata": {},
   "source": [
    "Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4782a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate([y.numpy() for _, y in train_ds])\n",
    "cw_values = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "cw = {int(i): float(w) for i, w in enumerate(cw_values)}  # convertim la float pur\n",
    "print(\"Class weights:\", cw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db785a0",
   "metadata": {},
   "source": [
    "Augmentare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e0902",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "train_ds = train_ds.map(lambda x,y: (data_aug(x), y)).prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb61e0c4",
   "metadata": {},
   "source": [
    "Creare model EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90647e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(*IMG_SIZE,3))\n",
    "base.trainable = False  # freeze\n",
    "\n",
    "inputs = Input(shape=(*IMG_SIZE,3))\n",
    "x = efficientnet.preprocess_input(inputs)  # normalize corect\n",
    "x = base(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Callback\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb805465",
   "metadata": {},
   "source": [
    "Antrenament Top 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45935854",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_top = model.fit(train_ds, validation_data=val_ds,\n",
    "                        epochs=EPOCHS_TOP, class_weight=cw, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2891ff59",
   "metadata": {},
   "source": [
    "Fine tuning: deblocare straturi superioare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b59c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.trainable = True\n",
    "fine_at = len(base.layers) - 20\n",
    "for layer in base.layers[:fine_at]:\n",
    "    layer.trainable = False\n",
    "for layer in base.layers[fine_at:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(train_ds, validation_data=val_ds,\n",
    "                         epochs=EPOCHS_FINE, class_weight=cw, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78400d8c",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc8edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(hs, labs):\n",
    "    plt.figure(figsize=(14,6))\n",
    "    for i,(h,l) in enumerate(zip(hs,labs)):\n",
    "        plt.subplot(2,1,1 if i<2 else 2)\n",
    "        plt.plot(h.history['accuracy'], label=f\"Train {l}\")\n",
    "        plt.plot(h.history['val_accuracy'], '--', label=f\"Val {l}\")\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot([history_top, history_fine], [\"Top only\", \"Fine-tuned\"])\n",
    "\n",
    "try:\n",
    "    model.save(\"EN_model.keras\", save_format=\"keras\")\n",
    "    print(\" Model salvat cu succes în formatul Keras.\")\n",
    "except TypeError as e:\n",
    "    print(\" Eroare la salvare completă:\", e)\n",
    "    print(\" Salvăm separat arhitectura și greutățile (fallback).\")\n",
    "\n",
    "    #  Salvare fallback (arhitectură + greutăți)\n",
    "    model_json = model.to_json()\n",
    "    with open(\"EN_model_architecture.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    model.save_weights(\"EN_model_weights.h5\")\n",
    "    print(\" Arhitectură și greutăți salvate separat.\")\n",
    "\n",
    "#  Obține etichetele reale și predicțiile\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in val_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "#  Raport clasificare\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "#  Matrice de confuzie\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\" Predicted Label\")\n",
    "plt.ylabel(\" True Label\")\n",
    "plt.title(\" Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN_Classic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
